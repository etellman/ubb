\documentclass[landscape]{exam}

\usepackage{2in1, lscape} 
\usepackage{units} 
\usepackage[fleqn]{amsmath}
\usepackage{float}
\usepackage{mdwlist}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{parskip}

\printanswers

\everymath{\displaystyle}

\printanswers

\title{Statistics \\ Week Fourteen}
\date{\today}
\author{}

\begin{document}

  \maketitle
  \tableofcontents

  \section{Homework 11}
  \begin{description}
    \item[31] Events are independent because
      \[
        P(\text{A and B}) = P(A) P(B)
      \]

      In reality, if you get into one, you have a higher chance of getting into
      the other one, so the estimate of $P(\text{A and B}) = 0.2$ may be a
      little conservative if the other two estimates are correct.


    \item[37] Draw a picture. Answer key:
      \begin{itemize*}
        \item had greater/less than wrong
        \item did $P(\text{A and B})$ instead of $P(A | B)$
      \end{itemize*}

  \end{description}
  \section{Confidence Intervals}

  \subsection{Election}

  500 person exit poll showing:
  \begin{itemize*}
    \item Democrat: 53
    \item Republican: 45
    \item Other: 2
  \end{itemize*}

  Can you call the race?

  \[
    sd \approx \sqrt{\frac{0.53 \cdot 0.47}{500}} = 0.02
  \]

  68\% of the time, the sample value will be within one standard deviation of
  the actual value. 
  
  You can say that you are 68\% confident that:
  \begin{itemize*}
    \item Democrat: between 0.51 and 0.55
    \item Republican: between 0.43 and 0.47
    \item Other: doesn't matter
  \end{itemize*}

  32\% of the time you'll be wrong, and you might declare the wrong winner.

  95\% of the time, the sample value will be within two standard deviations of
  the actual value. 
  
  You can say that you are 95\% confident that:
  \begin{itemize*}
    \item Democrat: between 0.49 and 0.57
    \item Republican: between 0.41 and 0.49
    \item Other: doesn't matter
  \end{itemize*}

  Now there is overlap, but you still can't declare a winner. To get more
  confident, you have to broaden the range.

  If you later in the day you get a bigger poll with 2000 people, the standard
  deviation goes down to:
  \[
    sd \approx \sqrt{\frac{0.53 \cdot 0.47}{2000}} = 0.01
  \]

  Now you can say that you are 95\% confident that:
  \begin{itemize*}
    \item Democrat: between 0.51 and 0.55
    \item Republican: between 0.43 and 0.47
    \item Other: doesn't matter
  \end{itemize*}

  You can also say that you are 99.7\% confident (3 standard deviations) that:
  \begin{itemize*}
    \item Democrat: between 0.50 and 0.56
    \item Republican: between 0.42 and 0.48
    \item Other: doesn't matter
  \end{itemize*}

  Now you can be confident in declaring a winner. Even if you are wrong, there
  is a chance that you have underestimated the Democrat count, so you have an
  even slimmer chance of being wrong in the wrong direction.

  \subsection{NFL Rushing}
  Often you don't know the actual mean and want to estimate it from the mean of
  a sample.

  Suppose you want to determine the average yards per rush in the NFL by taking
  an SRS of 20 rushes.

  The actual value is:
  \begin{align*}
    \mu    & \approx 4.12 \\
    \sigma & \approx 6.32 \\
  \end{align*}

  From the Central Limit Theorem, $\bar{x}$ has a Normal distribution with:
  \begin{align*}
    \mu         & = 4.12 \\
    s_{\bar{x}} & = \frac{\sigma}{\sqrt{20}} \\
                & \approx 1.41 \\
  \end{align*}

  \begin{itemize*}
    \item 68\% of the time $\bar{x}$ is within 1.41 of $\mu$.
    \item 95\% of the time $\bar{x}$ is within 2.82 of $\mu$.
  \end{itemize*}

  Turning this around:
  \begin{itemize*}
    \item 68\% of the time $\mu$ is within 1.41 of $\bar{x}$.
    \item 95\% of the time $\mu$ is within 2.82 of $\bar{x}$.
  \end{itemize*}

  If we take a random sample of size 20, we can calculate its mean and conclude
  that:
  \begin{itemize*}
    \item We can be 68\% confident that the actual value is in the range
      $\bar{x} \pm 1.41$
    \item We can be 95\% confident that the actual value is in the range
      $\bar{x} \pm 2.82$
  \end{itemize*}

  ``x\% confident'' means that x\% of the time when we take a sample of this
  size, the actual value of the parameter will be in this range.

  I did this for 10 different samples and got:

  \[
    \bar{x} = \{ 3.05, 4.20, 3.50, 3.70, 2.25, 4.25, 3.50, 3.90, 7.50, 2.50 \}
  \]

  Out of these trials, 2.25, 7.50, and 2.50 are more than 1 standard deviation
  from the actual mean and only 7.5 is more than 2 standard deviations from the
  actual mean.

  So it is safe to say that for example:
  \begin{itemize*}
    \item the actual value is $3.05 \pm 1.41$ (68\% confidence)
    \item the actual value is $3.05 \pm 2.82$ (95\% confidence)
  \end{itemize*}

  Note that the larger the range, the more confident you can be. 
  
  68\% confidence means that about 32\% of the time, you'll be wrong. For
  instance:

  \[
    2.25 \pm 1.41
  \] 

  is actually wrong.

  The general procedure is:
  \begin{enumerate*}
    \item decide how much you care about the result being correct (desired
      confidence)

    \item use Table A to find how many standard deviations away from the mean
      this value is. This is $z^*$.

    \item calculate the mean of the sample

    \item The actual value is: $\bar{x} \pm z^* \cdot s_{\bar{x}}$ with the
      desired confidence

  \end{enumerate*}

  notes:
  \begin{itemize}
    \item Assumes you know the standard deviation of the population. If you
      don't, you can use the standard deviation of the sample and get pretty
      close (student's T-test).

    \item Larger samples result in more precision.

    \item You can never be 100\% confident you have the right value.

    \item Smaller margin of error gives you less confidence.
  \end{itemize}


  \section{Hypothesis Testing}
  Another thing we can do with samples is test some hypothesis. The hypothesis
  is something like ``the mean is x.'' If the hypothesis was true, we calculate
  the probability of getting the result we got in the sample.

  For example suppose our hypothesis is that the average rush in the NFL is 5
  yards and we sampled 20 rushes and found that their average was 3.70. 3.70 is
  pretty far from 5.

  With 20 rushes, the standard deviation is:
  \begin{align*}
    s_{\bar{x}} & = \frac{\sigma}{\sqrt{20}} \\
                & \approx 1.41 \\
  \end{align*}

  Calculate the z-score for the observed $\bar{x}$:
  \begin{align*}
    z_{\bar{x}} & = \frac{3.70 - 5.0}{1.41} \\
                & \approx -0.92 \\
  \end{align*}

  From table A, the chance of getting a result at least $0.92$ standard
  deviations below the mean is approximately 18\%. Since this is a pretty big
  number, we can't be very confident in ruling out the possibility that the
  actual mean is 5.

  Suppose we instead theorized that the actual mean was 7. With this mean, the
  z-score is:
  \begin{align*}
    z_{\bar{x}} & = \frac{3.70 - 7.0}{1.41} \\
                & \approx -2.34 \\
  \end{align*}

  From table A, the chance of getting a result at least $2.34$ standard
  deviations below the mean is approximately 1\%. Since this is a pretty small
  number, we can't be fairly confident in ruling out the possibility that the
  actual mean is 7. If the mean was really 7, then only 1 out of 100 times we
  took a sample of 20 would we get an $\bar{x}$ as low as 3.7.

  notes:
  \begin{itemize*}
    \item With hypothesis testing, the goal is to try to rule out the
      hypothesis. If we get a result that is very unlikely if the hypothesis is
      true, then we can assume with high confidence that the hypothesis is
      false.

    \item The probability of the observed result, assuming the hypothesis is
      true is the P-value. A low P-value means we can be confident in ruling out
      the hypothesis. A high P-value means that the hypothesis might be true and
      we can't rule it out.

  \end{itemize*}

  \section{Examples}

  \subsection{Education and Salary}

  From the 2012 WA population survey (week 2), the mean income from wages for
  people that worked was:
  \begin{align*}
    \mu    & = 39,148 \\
    \sigma & = 31,884 \\
  \end{align*}

  The null hypothesis is that a bachelor's degree make no more than people
  without a bachelor's degree (1-sided).

  This example doesn't start with a normal distribution, so it doesn't quite
  follow the rules.

  With a sample size of 20:
  \begin{align*}
    \sigma_{\bar{x}} & = 31,884 / \sqrt{20} \\
                     & \approx 7129 \\
  \end{align*}

  Taking a random sample of 20 people with at least a bachelor's degree, 
  $\bar{x} = 53,943$

  Calculate z-value:
  \begin{align*}
    z & = \frac{53,943 - 31,884}{7129} \\
      & \approx 2.08 \\
  \end{align*}

  Use table A to find P-value of 0.02. We can reject the null hypothesis with a
  P-value of 0.02. There is only a 2\% chance of getting a value this large
  purely by chance if the null hypothesis is true and a degree doesn't help you
  earn more money.

  With a sample size of 100 college educated people:
  \begin{align*}
    \bar{x}          & = 54,866 \\
    \sigma_{\bar{x}} & \approx 4509 \\
    z                & \approx 3.49 \\
    p                & \approx 0.0002 \\
  \end{align*}

  With this large of a sample, there is only a 0.02\% chance of getting this
  large of a value purely by chance if education doesn't help you earn more
  money.


  \subsection{NBA Field Goal Percentage}

  For all players:
  \begin{align*}
    \mu    & \approx 0.43 \\
    \sigma & \approx 0.10 \\
  \end{align*}

  With a sample of 30 centers:
  \begin{align*}
    \bar{x}          & \approx 0.47 \\
    \sigma_{\bar{x}} & \approx 0.023 \\
    z                & \approx 1.84 \\
    p                & \approx 0.033 \\
  \end{align*}

  For a 2-sided null hypothesis (centers have a different field goal percentage than
  everyone else) we can reject the null hypothesis at a P-value of 0.066. There
  is only a 0.066 probability of centers being $\pm 1.84$ standard deviations from the
  mean.

  For a 1-sided null hypothesis (centers have a better field goal percentage
  than everyone else) we can reject the null hypothesis at a P-value of 0.033.
  There is only a 0.033 probability of centers being $1.84$ standard deviations
  above the mean.

  With a sample of 50 centers:
  \begin{align*}
    \bar{x}          & \approx 0.49 \\
    \sigma_{\bar{x}} & \approx 0.018 \\
    z                & \approx 2.19 \\
    p                & \approx 0.014 \\
  \end{align*}

  With a larger sample, we can be more confident of the result.

  \subsection{Adrian Peterson}
  All rushers:
  \begin{align*}
    \mu    & \approx 4.12 \\
    \sigma & \approx 6.32 \\
  \end{align*}

  Adrian Peterson, sample 500 rushes
  \begin{align*}
    \bar{x}          & \approx 4.64 \\
    \sigma_{\bar{x}} & \approx 0.184 \\
    z                & \approx 2.85 \\
    p                & \approx 0.002 \\
  \end{align*}

  notes
  \begin{itemize*}
    \item actual mean for AP is 4.95
    \item need large sample because standard deviation is so large
    \item data is approximately normal
  \end{itemize*}

  \subsection{Luciana De Clerk}

  After nurse was present at death of baby, someone noticed that she was often
  present at deaths. The director of the hospital looked through the files for
  other similar unexplained deaths. 

  \begin{table}
    \centering
    \begin{tabular}{lrrr}[H]
      \toprule
      shifts        & without incident & with incident & total \\
      \midrule
      without Lucia & 887              & 0             & 887 \\
      with Lucia    & 134              & 8             & 142 \\
      Total         & 1,021            & 8             & 1,029 \\
      \bottomrule
    \end{tabular}
    \caption{Luciana de Berk}
    \label{tab:ldb1}
  \end{table}

  Amateur statistician testified at trial that P-value for this hospital was
  0.00000029854. He did this for the other two hospitals where Lucia worked and
  got P-values of 0.0715 and 0.0136, both with the unusual but still plausible
  range.

  Multiplying all three P-values together gives: 1 in 342 million and Lucia was
  convicted.

  She spent 13 years in prison, and finally was released based on:
  \begin{itemize*}

    \item there were other similar cases ``with incident'' which the prosecution
      didn't mention. Part of the definition of ``with incident'' was ``Lucia
      present.''

    \item some of the cases used in the trial had actually occurred when Lucia
      had been out sick.

    \item the prosecution didn't compute new P-values taking this stuff into
      consideration

    \item multiplying P-values doesn't make sense. If a particular nurse is in
      the bottom 10\% of nurses, for example, she'll show up in the bottom 10\%
      at all three hospitals where she works. This doesn't put her in the bottom
      0.1 percent ($0.1^3$) of all nurses. Maybe Lucia always took the tough
      cases, worked more night shifts than average, or just wasn't a to nurse.

      The P-values aren't independent.

    \item no evidence of any poison, etc. was ever found. The theory of Lucia
      administering an OD was disproved with medical evidence. 
  \end{itemize*}

  \section{Check Your Skills}
  \begin{description}
    \item[14.1] 
      \begin{enumerate}[(a)]

        \item $ sd = \frac{60}{\sqrt{840}} \approx \boxed{ 2.07 } $

        \item 4.14

        \item 267.86 to 276.14

      \end{enumerate}

    \item[14.3] 97.5\% is 2.5\% less than 100\%. The value might be either very low
      or very high, so we're looking for the $z^*$ value that corresponds to
      1.25\%. From Table A, this is $z^* \approx 2.24$. A z-score less than
      -2.25 or greater than 2.25 will satisfy the requirements.

    \item[14.4]
      For a 90\% confidence interval and Table A, $z^* \approx 1.645$. None of
      the measurements should be more than 1.645 standard deviations from the
      mean.

      In conductivity units, this corresponds to $\pm 1.645 \cdot 0.2 = \pm
      0.329$. All of the measurements should be between 4.67 and 5.33.

      They all are, so they can say with 95\% confidence that everything is
      fine with what they are providing to the customers.

      If any of the samples had been outside this range, we would not have had
      95\% confidence that the liquid actually had a mean of 5.

    \item[14.5]
      The mean for the sample is 105.84. 

      For a 99\% confidence interval, $z^* = 2.576$. Converting this to IQ
      scores gives:
      \[
        iq = 2.576 \frac{15}{\sqrt{31}} \approx 6.94
      \]

      We can be 99\% confident that the actual mean is between and 98.90 and 112.78

    \item[14.6]

      part b:

      \begin{align*}
        \sigma_{\bar{x}} & = \frac{30}{\sqrt{25}} \\
                         & = 6 \\
        \\
        z_{118.6}        & = \frac{118.6 - 115}{6} \\
                         & \approx 0.58 \\
        P_{118.6}        & \approx 0.72 \\
        \\
        z_{125.8}        & = \frac{125.8 - 115}{6} \\
                         & \approx 1.8 \\
        P_{125.8}        & \approx 0.036 \\
      \end{align*}

      About 72\% of the time a value as large as 118.6 will come up by random
      chance for the sample. A value as large as 125.8 will only come up about
      3.6\% of the time by chance.
  \end{description}
\end{document}

