\documentclass[landscape]{exam}

\usepackage{2in1, lscape} 
\usepackage{units} 
\usepackage[fleqn]{amsmath}
\usepackage{float}
\usepackage{mdwlist}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{parskip}

\printanswers

\everymath{\displaystyle}

\printanswers

\title{Statistics \\ Week Fourteen}
\date{\today}
\author{}

\begin{document}

  \maketitle
  \tableofcontents

  \section{Homework 11}
  \begin{description}
    \item[31] Events are independent because

      With dependent events:
      \begin{align*}
        P( \text{A } | \text{ B} ) & = \frac{ P(\text{A and B}) }{ P(B) } \\
        P( \text{A and B} )        & = P( \text{A } | \text{ B} ) P(B) \\
      \end{align*}

      In this example:
      \[
        P(\text{A and B}) = P(A) P(B)
      \]

      Substituting:
      \begin{align*}
        P(A) P(B) & = P( \text{A } | \text{ B} ) P(B) \\
        P(A)      & = P( \text{A } | \text{ B} ) \\
      \end{align*}

      and the events are independent.

      In reality, if you get into one, you have a higher chance of getting into
      the other one, so the estimate of $P(\text{A and B}) = 0.2$ may be a
      little conservative if the other two estimates are correct.


    \item[37] Draw a picture. Answer key:
      \begin{itemize*}
        \item had greater/less than wrong
        \item did $P(\text{A and B})$ instead of $P(A | B)$
      \end{itemize*}

  \end{description}

  \section{Roulette}
  Discuss box models for roulette.

  \section{Confidence Intervals}

  \subsection{Election}

  500 person exit poll showing:
  \begin{itemize*}
    \item Alice: 265 (53\%)
    \item Bob: 235 (47\%)
  \end{itemize*}

  Can you call the race?

  \begin{align*}
    se & = \sqrt{500 \cdot 0.53 \cdot 0.47} \\
       & \approx \unit[11]{people} \\
       \\
    frac{11}{500} &\approx 2\%
  \end{align*}

  68\% of the time, the sample value will be within one standard deviation of
  the actual value. 
  
  You can say that you are 68\% confident that:
  \begin{itemize*}
    \item Alice: between 0.51 and 0.55
    \item Bob: between 0.45 and 0.49
  \end{itemize*}

  32\% of the time you'll be wrong, and you might declare the wrong winner.

  95\% of the time, the sample value will be within two standard deviations of
  the actual value. 
  
  You can say that you are 95\% confident that:
  \begin{itemize*}
    \item Alice: between 0.49 and 0.57
    \item Bob: between 0.43 and 0.51
  \end{itemize*}

  Now there is overlap, but you still can't declare a winner. To get more
  confident, you have to broaden the range.

  If you later in the day you get a bigger poll with 2000 people, the standard
  deviation goes down to:
  \begin{align*}
    se & = \sqrt{2000 \cdot 0.53 \cdot 0.47} \\
       & \approx \unit[22]{people} \\
       \\
    frac{22}{2000} &\approx 1\%
  \end{align*}

  Now you can say that you are 95\% confident that:
  \begin{itemize*}
    \item Alice: between 0.52 and 0.54
    \item Bob: between 0.46 and 0.48
  \end{itemize*}

  You can also say that you are 99.7\% confident (3 standard deviations) that:
  \begin{itemize*}
    \item Alice: between 0.50 and 0.56
    \item Bob: between 0.44 and 0.50
  \end{itemize*}

  Now you can be confident in declaring a winner. Even if you are wrong, there
  is a chance that you have underestimated the Democrat count, so you have an
  even slimmer chance of being wrong in the wrong direction.

  \subsection{NFL Rushing}
  Often you don't know the actual mean and want to estimate it from the mean of
  a sample.

  Suppose you want to determine the average yards per rush in the NFL by taking
  an SRS of 20 rushes.

  The actual value is:
  \begin{align*}
    \mu    & \approx 4.12 \\
    \sigma & \approx 6.32 \\
  \end{align*}

  From the Central Limit Theorem, $\bar{x}$ has a Normal distribution with:
  \begin{align*}
    \mu         & = 4.12 \\
    s_{\bar{x}} & = \frac{\sigma}{\sqrt{20}} \\
                & \approx 1.41 \\
  \end{align*}

  \begin{itemize*}
    \item 68\% of the time $\bar{x}$ is within 1.41 of $\mu$.
    \item 95\% of the time $\bar{x}$ is within 2.82 of $\mu$.
  \end{itemize*}

  Turning this around:
  \begin{itemize*}
    \item 68\% of the time $\mu$ is within 1.41 of $\bar{x}$.
    \item 95\% of the time $\mu$ is within 2.82 of $\bar{x}$.
  \end{itemize*}

  If we take a random sample of size 20, we can calculate its mean and conclude
  that:
  \begin{itemize*}
    \item We can be 68\% confident that the actual value is in the range
      $\bar{x} \pm 1.41$
    \item We can be 95\% confident that the actual value is in the range
      $\bar{x} \pm 2.82$
  \end{itemize*}

  ``x\% confident'' means that x\% of the time when we take a sample of this
  size, the actual value of the parameter will be in this range.

  I did this for 10 different samples and got:

  \[
    \bar{x} = \{ 3.05, 4.20, 3.50, 3.70, 2.25, 4.25, 3.50, 3.90, 7.50, 2.50 \}
  \]

  Out of these trials, 2.25, 7.50, and 2.50 are more than 1 standard deviation
  from the actual mean and only 7.5 is more than 2 standard deviations from the
  actual mean.

  So it is safe to say that for example:
  \begin{itemize*}
    \item the actual value is $3.05 \pm 1.41$ (68\% confidence)
    \item the actual value is $3.05 \pm 2.82$ (95\% confidence)
  \end{itemize*}

  Note that the larger the range, the more confident you can be. 
  
  68\% confidence means that about 32\% of the time, you'll be wrong. For
  instance:

  \[
    2.25 \pm 1.41
  \] 

  is actually wrong.

  \subsection{Notes}

  \begin{itemize}
    \item There are two parts to an estimate:
      \begin{itemize*}
        \item interval: $estimate \pm error$
        \item confidence level: probability that the interval captures the actual
          parameter
      \end{itemize*}

    \item A bigger margin of error goes with higher confidence.

  \end{itemize}

  The general procedure is:
  \begin{enumerate*}
    \item decide how much you care about the result being correct (desired
      confidence)

    \item use Table A to find how many standard deviations away from the mean
      this value is. This is $z^*$.

    \item calculate the mean of the sample

    \item The actual value is: $\bar{x} \pm z^* \cdot s_{\bar{x}}$ with the
      desired confidence

  \end{enumerate*}

  notes:
  \begin{itemize}
    \item Assumes you know the standard deviation of the population. If you
      don't, you can use the standard deviation of the sample and get pretty
      close (student's T-test).

    \item Larger samples result in more precision.

    \item You can never be 100\% confident you have the right value.

    \item Smaller margin of error gives you less confidence.
  \end{itemize}

  \subsection{Check Your Skills}
  \begin{description}
    \item[14.1] 
      \begin{enumerate}[(a)]

        \item $ sd = \frac{60}{\sqrt{840}} \approx 2.07$

        \item 4.14

        \item 267.86 to 276.14

      \end{enumerate}

    \item[14.3] 97.5\% is 2.5\% less than 100\%. The value might be either very low
      or very high, so we're looking for the $z^*$ value that corresponds to
      1.25\%. From Table A, this is $z^* \approx 2.24$. A z-score less than
      -2.25 or greater than 2.25 will satisfy the requirements.

    \item[14.4]
      For a 90\% confidence interval and Table A, $z^* \approx 1.645$. None of
      the measurements should be more than 1.645 standard deviations from the
      mean.

      In conductivity units, this corresponds to $\pm 1.645 \cdot 0.2 = \pm
      0.329$. All of the measurements should be between 4.67 and 5.33.

      They all are, so they can say with 95\% confidence that everything is
      fine with what they are providing to the customers.

      If any of the samples had been outside this range, we would not have had
      95\% confidence that the liquid actually had a mean of 5.

    \item[14.5]
      The mean for the sample is 105.84. 

      For a 99\% confidence interval, $z^* = 2.576$. Converting this to IQ
      scores gives:
      \[
        iq = 2.576 \frac{15}{\sqrt{31}} \approx 6.94
      \]

      We can be 99\% confident that the actual mean is between and 98.90 and 112.78

    \end{description}

  \section{Hypothesis Testing}

  \subsection{General Idea}
  \begin{itemize}
    \item have some theory about a parameter ($\mu = 17$) (null hypothesis)
    \item measure the relevant statistic ($\bar{x = 25}$)
    \item if $\bar{x}$ is very unlikely to occur if null hypothesis is true, you
      can reasonably conclude that null hypothesis is false
    \item Draw normal curve with shaded regions for one and two sided
      hypothesis.
  \end{itemize}

  \subsection{Rushing Example}

  \subsubsection{Hypothesis One}
  For example suppose our hypothesis is that the average rush in the NFL is 5
  yards and we sampled 20 rushes and found that their average was 3.70. 3.70 is
  pretty far from 5.

  We now from past seasons that $\sigma \approx \unit[6.3]{yd}$

  With 20 rushes, the standard deviation is:
  \begin{align*}
    s_{20} & = \frac{6.3}{\sqrt{20}} \\
           & \approx \unit[1.41]{yd} \\
  \end{align*}

  Calculate the z-score for the observed $\bar{x}$:
  \begin{align*}
    z_{\bar{x}} & = \frac{3.70 - 5.0}{1.41} \\
                & \approx -0.92 \\
  \end{align*}

  From table A, the chance of getting a result at least $0.92$ standard
  deviations below the mean is approximately 18\%. Since this is a pretty big
  number, we can't be very confident in ruling out the possibility that the
  actual mean is 5.

  \subsubsection{Hypothesis Two}
  Suppose we instead theorized that the actual mean was 7. With this mean, the
  z-score is:
  \begin{align*}
    z_{\bar{x}} & = \frac{3.70 - 7.0}{1.41} \\
                & \approx -2.34 \\
  \end{align*}

  From table A, the chance of getting a result at least $2.34$ standard
  deviations below the mean is approximately 1\%. Since this is a pretty small
  number, we can be fairly confident in ruling out the possibility that the
  actual mean is 7. If the mean was really 7, then only 1 out of 100 times we
  took a sample of 20 would we get an $\bar{x}$ as low as 3.7.

  \subsection{Procedure and Notes}
  \begin{itemize}
    \item With hypothesis testing, the goal is to try to rule out the null
      hypothesis. If we get a result that is very unlikely if the hypothesis is
      true, then we can assume with high confidence that the hypothesis is
      false.

    \item The probability of the observed result, assuming the hypothesis is
      true is the P-value. A low P-value means we can be confident in ruling out
      the hypothesis. A high P-value means that the hypothesis might be true and
      we can't rule it out.

    \item P-value from first example was 0.18. P-value from second example was
      0.01.

    \item you can never be sure the null hypothesis is incorrect

    \item A ``statistically significant at X'' result means that you got a P-value
      less than X. Common choices for $X$ are 0.05 and 0.01. You can pick one
      that is appropriate for your domain.

    \item ``Statistically Significant'' doesn't mean ``Actually Significant.'' A
      very small difference might be statistically significant but
      uninteresting.

    \item With a two-sided test, the hypothesis is something like ``the average
      yards rushing is 7.'' You rule out the null hypothesis if your $\bar{x}$
      is much larger or smaller than 7.

    \item With a two-sided test, the hypothesis is something like ``the average
      yards rushing is more than 7.'' You rule out the null hypothesis if your $\bar{x}$
      is much smaller than 7.

    \item For now, assume you have standard deviation from population and
      population is fairly Normally distributed

  \end{itemize}

  \subsection{Examples}

  \subsubsection{Education and Salary}

  From the 2012 WA population survey (week 2), the mean income from wages for
  people that worked (wage greater than 0) was:
  \begin{align*}
    \mu    & = 46,122 \\
    \sigma & = 52,071 \\
  \end{align*}

  The null hypothesis is that people without a degree make as much as people
  with a degree.

  This example doesn't start with a normal distribution, so it doesn't quite
  follow the rules. It doesn't matter if you use a large sample size. With a
  sample size less than 100 there was quite a bit of variation in the p-value
  from 0.01 to 0.000001, depending on the sample.

  With a sample size of 500:
  \begin{align*}
    s_{500} & = 52,071 / \sqrt{500} \\
                     & \approx 2,329 \\
  \end{align*}

  Taking a random sample of 500 people with at least an associate's degree, 
  $\bar{x} = \$64,792$

  Calculate z-value:
  \begin{align*}
    z & = \frac{64,792 - 46,122}{2,329} \\
      & \approx 8.02 \\
  \end{align*}

  This is a P-value of approximately $5 \times 10^{-16}$. There is essentially
  zero chance of being this many standard deviations away from the mean for all
  people just by chance. We can safely conclude that getting a degree helps you
  make more money.

  \subsubsection{NBA Field Goal Percentage}

  For all players:
  \begin{align*}
    \mu    & \approx 0.43 \\
    \sigma & \approx 0.10 \\
  \end{align*}

  With a sample of 30 centers:
  \begin{align*}
    \bar{x}          & \approx 0.47 \\
    \sigma_{\bar{x}} & \approx 0.023 \\
    z                & \approx 1.84 \\
    p                & \approx 0.033 \\
  \end{align*}

  For a 2-sided null hypothesis (centers have a different field goal percentage
  than everyone else) we can reject the null hypothesis at a P-value of 0.066.
  There is only a 0.066 probability of centers being $\pm 1.84$ standard
  deviations from the
  mean.

  For a 1-sided null hypothesis (centers have a better field goal percentage
  than everyone else) we can reject the null hypothesis at a P-value of 0.033.
  There is only a 0.033 probability of centers being $1.84$ standard deviations
  above the mean.

  With a sample of 50 centers:
  \begin{align*}
    \bar{x}          & \approx 0.49 \\
    \sigma_{\bar{x}} & \approx 0.018 \\
    z                & \approx 2.19 \\
    p                & \approx 0.014 \\
  \end{align*}

  With a larger sample, we can be more confident of the result.

  \subsubsection{Adrian Peterson}
  All rushers:
  \begin{align*}
    \mu    & \approx 4.12 \\
    \sigma & \approx 6.32 \\
  \end{align*}

  Adrian Peterson, sample 500 rushes
  \begin{align*}
    \bar{x}          & \approx 4.64 \\
    \sigma_{\bar{x}} & \approx 0.184 \\
    z                & \approx 2.85 \\
    p                & \approx 0.002 \\
  \end{align*}

  notes
  \begin{itemize*}
    \item actual mean for AP is 4.95
    \item need large sample because standard deviation is so large
    \item data is approximately normal
  \end{itemize*}

  \subsection{Check Your Skills}
  \begin{description}
    \item[14.6]

      part b:

      \begin{align*}
        \sigma_{\bar{x}} & = \frac{30}{\sqrt{25}} \\
                         & = 6 \\
        \\
        z_{118.6}        & = \frac{118.6 - 115}{6} \\
                         & \approx 0.58 \\
        P_{118.6}        & \approx 0.72 \\
        \\
        z_{125.8}        & = \frac{125.8 - 115}{6} \\
                         & \approx 1.8 \\
        P_{125.8}        & \approx 0.036 \\
      \end{align*}

      About 72\% of the time a value as large as 118.6 will come up by random
      chance for the sample. A value as large as 125.8 will only come up about
      3.6\% of the time by chance.

    \item[14.7]
      \begin{align*}
        s_6 &= \frac{0.2}{\sqrt{6}} \\
        &\approx 0.082 \\
        \\
        z_{4.98} & = \frac{4.98 - 5}{0.082} \\
                 & \approx -0.24 \\
        \\
        z_{4.7} & = \frac{4.7 - 5}{0.082} \\
                & \approx -3.7 \\
      \end{align*}
  \end{description}
  \subsection{Luciana De Clerk}

  After nurse was present at death of baby, someone noticed that she was often
  present at deaths. The director of the hospital looked through the files for
  other similar unexplained deaths. 

  \begin{table}[H]
    \centering
    \begin{tabular}{lrrr}
      \toprule
      shifts        & without incident & with incident & total \\
      \midrule
      without Lucia & 887              & 0             & 887 \\
      with Lucia    & 134              & 8             & 142 \\
      Total         & 1,021            & 8             & 1,029 \\
      \bottomrule
    \end{tabular}
    \caption{Luciana de Berk}
    \label{tab:ldb1}
  \end{table}

  Amateur statistician testified at trial that P-value for this hospital was
  0.00000029854. He did this for the other two hospitals where Lucia worked and
  got P-values of 0.0715 and 0.0136, both with the unusual but still plausible
  range.

  Multiplying all three P-values together gives: 1 in 342 million and Lucia was
  convicted.

  She spent 13 years in prison, and finally was released based on:
  \begin{itemize*}

    \item there were other similar cases ``with incident'' which the prosecution
      didn't mention. Part of the definition of ``with incident'' was ``Lucia
      present.''

    \item some of the cases used in the trial had actually occurred when Lucia
      had been out sick.

    \item the prosecution didn't compute new P-values taking this stuff into
      consideration

    \item multiplying P-values doesn't make sense. If a particular nurse is in
      the bottom 10\% of nurses, for example, she'll show up in the bottom 10\%
      at all three hospitals where she works. This doesn't put her in the bottom
      0.1 percent ($0.1^3$) of all nurses. Maybe Lucia always took the tough
      cases, worked more night shifts than average, or just wasn't a to nurse.

      The P-values aren't independent.

    \item no evidence of any poison, etc. was ever found. The theory of Lucia
      administering an OD was disproved with medical evidence. 
  \end{itemize*}

\end{document}

